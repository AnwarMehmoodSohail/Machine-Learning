{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3479efc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Step 0: Install & Import Libraries\n",
    "# ===============================\n",
    "# Make sure to install: transformers, torch, sklearn, pandas\n",
    "# pip install transformers torch scikit-learn pandas\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ce7eda",
   "metadata": {},
   "source": [
    "Step 1: Generate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c46fe1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# Step 1: Generate Dataset\n",
    "# ===============================\n",
    "sentences = [\n",
    "    \"I love this movie\", \"This film was amazing\", \"I enjoyed every moment\",\n",
    "    \"The acting was great\", \"What a fantastic experience\",\n",
    "    \"Absolutely wonderful movie\", \"The story was touching\", \"I liked the characters\",\n",
    "    \"Very entertaining film\", \"This movie made me happy\",\n",
    "    \n",
    "    \"I hate this movie\", \"This film was terrible\", \"I disliked every moment\",\n",
    "    \"The acting was awful\", \"What a boring experience\",\n",
    "    \"Absolutely horrible movie\", \"The story was weak\", \"I hated the characters\",\n",
    "    \"Very disappointing film\", \"This movie made me angry\"\n",
    "] * 5  # 100 samples\n",
    "\n",
    "labels = [\"positive\"] * 50 + [\"negative\"] * 50\n",
    "\n",
    "df = pd.DataFrame({\"sentence\": sentences, \"sentiment\": labels})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8186bff1",
   "metadata": {},
   "source": [
    "Step 2: Encode Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa8ebbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ===============================\n",
    "# Step 2: Encode Labels\n",
    "# ===============================\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"label\"] = label_encoder.fit_transform(df[\"sentiment\"])  # positive=1, negative=0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8281b5e5",
   "metadata": {},
   "source": [
    "Step 3: Trainâ€“Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70ce8e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# Step 3: Train-Test Split\n",
    "# ===============================\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df[\"sentence\"], df[\"label\"], test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8680a71a",
   "metadata": {},
   "source": [
    "Step 4: Load BERT Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0b6e9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
      "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
      "You are not authenticated with the Hugging Face Hub in this notebook.\n",
      "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===============================\n",
    "# Step 4: Load BERT Tokenizer\n",
    "# ===============================\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Tokenize and encode sequences\n",
    "max_len = 32  # maximum sequence length\n",
    "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True, max_length=max_len)\n",
    "test_encodings = tokenizer(list(test_texts), truncation=True, padding=True, max_length=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68149b58",
   "metadata": {},
   "source": [
    "Step 5: Create PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f7adbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# Step 5: Create PyTorch Dataset\n",
    "# ===============================\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "train_dataset = SentimentDataset(train_encodings, list(train_labels))\n",
    "test_dataset = SentimentDataset(test_encodings, list(test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43969d05",
   "metadata": {},
   "source": [
    "Step 6: Load BERT Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ace420c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===============================\n",
    "# Step 6: Load Pretrained BERT Model\n",
    "# ===============================\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc15d221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# Step 7: DataLoader and Optimizer\n",
    "# ===============================\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690e8d08",
   "metadata": {},
   "source": [
    "Step 8: Train BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8b58308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "Loss: 0.7094\n",
      "Epoch 2/3\n",
      "Loss: 0.7371\n",
      "Epoch 3/3\n",
      "Loss: 0.7351\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Step 8: Training Loop\n",
    "# ===============================\n",
    "model.train()\n",
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786b2c51",
   "metadata": {},
   "source": [
    "Step 09: Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d895c3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===============================\n",
    "# Step 9: Evaluation\n",
    "# ===============================\n",
    "model.eval()\n",
    "preds = []\n",
    "true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        \n",
    "        preds.extend(predictions.cpu().numpy())\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "accuracy = accuracy_score(true_labels, preds)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102779a0",
   "metadata": {},
   "source": [
    "Step 10: Predict on New Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a0adea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n",
      "Positive\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Step 10: Predict New Sentences\n",
    "# ===============================\n",
    "def predict_sentiment(text):\n",
    "    model.eval()\n",
    "    encoding = tokenizer(text, truncation=True, padding=True, max_length=max_len, return_tensors=\"pt\")\n",
    "    encoding = {key: val.to(device) for key, val in encoding.items()}\n",
    "    with torch.no_grad():\n",
    "        output = model(**encoding)\n",
    "        prediction = torch.argmax(output.logits, dim=-1).item()\n",
    "    return \"Positive\" if prediction == 1 else \"Negative\"\n",
    "\n",
    "# Test\n",
    "print(predict_sentiment(\"I really enjoyed this movie\"))\n",
    "print(predict_sentiment(\"This film was very boring\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
